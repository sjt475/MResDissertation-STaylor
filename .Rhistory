"X2_Ambivalence1T1_8",
"OMC_7")
pnewnames <- c("AC1",
"AC2",
"AC3")
setnames(data_p, poldnames, pnewnames, skip_absent=TRUE)
## Attention Checks
#first 10 ppts did not see 2 attention checks - score as passed
first_ten <- c('60ef556c18ea57549dd70887', #list of first 10 ppts
'5ea8346c071ad806fc1f7e60',
'61111383a154ecf921c483ca',
'610fcc1016c8173f7267d48f',
'5d678553169dd60001566773',
'58061b34c7b1100001138a1e',
'5dc373b7f7353027d3177117',
'611122dfdc2b5feb2c9dd19e',
'61033ccc38ddc6fa030ea1e7',
'611101a4429a8f51506c519c')
data_p$AC1 <- ifelse(is.element(data_p$PROLIFIC_PID, first_ten),
7,
data_p$AC1)
data_p$AC2 <- ifelse(is.element(data_p$PROLIFIC_PID, first_ten),
7,
data_p$AC2)
#student sample did not have attention checks - score as passed
#rename columns
poldnames <- c("X1_Ambivalence1T1_8",
"X2_Ambivalence1T1_8",
"OMC_7")
pnewnames <- c("AC1",
"AC2",
"AC3")
setnames(data_s, poldnames, pnewnames, skip_absent=TRUE)
data_s$AC1 <- 7
data_s$AC2 <- 7
data_s$AC3 <- 1
## Merge datasets
#create variable to distinguish between student and prolific samples
data_s$Source <- 1 #student sample
data_p$Source <- 2 #prolific sample
variables <- c("Progress", #select variables necessary for analysis
"Duration..in.seconds.",
"Finished",
"ResponseId",
grep("Consent", names(data_p), value=TRUE),
grep("Content", names(data_p), value=TRUE),
grep("Ambivalence", names(data_p), value=TRUE),
grep("Certainty", names(data_p), value=TRUE),
grep("FE", names(data_p), value=TRUE),
grep("RE", names(data_p), value=TRUE),
grep("DB", names(data_p), value=TRUE),
grep("OMC", names(data_p), value=TRUE),
grep("NFC", names(data_p), value=TRUE),
"AC1",
"AC2",
"AC3",
"Age",
"Gender",
"Nationality",
"Education",
"Manipulation.Check",
"Purpose",
"Comments",
"Source")
data_pa <- data_p[variables]
data_sa <- data_s[variables]
data <- rbind(data_pa, data_sa)
variables <- c("Progress", #identify numeric variables
"Duration..in.seconds.",
"Finished",
grep("Consent", names(data_p), value=TRUE),
grep("Content", names(data_p), value=TRUE),
grep("Ambivalence", names(data_p), value=TRUE),
grep("Certainty", names(data_p), value=TRUE),
grep("FE", names(data_p), value=TRUE),
grep("RE", names(data_p), value=TRUE),
grep("DB", names(data_p), value=TRUE),
grep("OMC", names(data_p), value=TRUE),
grep("NFC", names(data_p), value=TRUE),
"AC1",
"AC2",
"AC3",
"Age",
"Nationality",
"Education",
"Manipulation.Check",
"Source")
data[variables] <- lapply(data[variables], as.numeric) #change numeric variables to numbers
data$Duration..in.seconds. <- data$Duration..in.seconds./60
data$ScaledDuration <- scale(data$Duration..in.seconds.)
setnames(data, "Duration..in.seconds.", "Duration", skip_absent=TRUE) #rename to reflect unit change (secs -> minutes)
setnames(data, "REPrac_1", "REPrac", skip_absent=TRUE) #rename for consistency with DB
setnames(data, "DBPrac_4", "DBPrac", skip_absent=TRUE) #rename for consistency with RE
#count number of failed attention checks (+1 to AChecks for each failure)
data$AChecks <- 0 #initally 3
data$AChecks <- ifelse(data$AC1 != 7,
data$AChecks+1,
data$AChecks)
data$AChecks <- ifelse(data$AC2 != 7,
data$AChecks+1,
data$AChecks)
data$AChecks <- ifelse(data$AC3 != 1,
data$AChecks+1,
data$AChecks)
data$AChecks <- as.numeric(data$AChecks)
data_raw <- data #save copy of raw data
## Exclusions
data <- subset(data,
Consent_1==1 & Consent_2==1 & Consent_3==1
& Consent_4==1 & Consent_5==1 & Consent_6==1
& Consent_7==1 & Consent_8==1
& (Nationality!=0 | is.na(Nationality)) #identify as British
& Progress==100 & Finished==1 #did not fish
& (AChecks<=1 | is.na(AChecks)) #failed 1 or fewer attention checks
& between(ScaledDuration, -3, 3)
& Manipulation.Check!=0) #not outlier in terms of duration)
data <- select(data, -c(FE5_1, FE6_1)) #remove removed first estimates
## Convert second estimates to "long" form and add condition
SEVariables <- c("ResponseId", #variables necessary to transform Second Estimates
grep("RE", names(data), value=TRUE),
grep("DB", names(data), value=TRUE))
data_se <- data[SEVariables] #pull necessary variables
qID <- c("1_1", "2_1", "3_1", "4_1", "5_1", "6_1", "7_1", "8_1", "9_1", "10_1",
"11_1", "12_1", "13_1", "14_1", "15_1", "16_1", "17_1", "18_1", "19_1", "20_1", "21_1")
#create dataframe (data_ses) that stores second estimates
data_se2 <- data.frame(data_se$ResponseId, data_se$REPrac, data_se$DBPrac)
data_se3 <- gather(data_se2, Condition, SEPrac, 2:3)
data_ses <- subset(data_se3, SEPrac != "")
setnames(data_ses, "data_se.ResponseId", "ResponseId", skip_absent=TRUE) #rename for consistency with data_se3
#loop merging second estimates from both conditions into one variable matched to participants
for (i in qID){
RE <- paste("RE", i, sep="")
DB <- paste("DB", i, sep="")
data_se2 <- data.frame(data_se$ResponseId, data_se[, RE], data_se[, DB])
data_se3 <- gather(data_se2, Condition, SE, 2:3)
data_se3 <- subset(data_se3, SE != "")
data_se3 <- data_se3[-c(2)]
setnames(data_se3, "data_se.ResponseId", "ResponseId", skip_absent=TRUE) #rename for consistency with data_ses
data_ses <- merge(data_ses, data_se3, by = "ResponseId")
}
#rename columns
newnames <- c("ResponseId", "Condition", "SEPrac", "SE1_1", "SE2_1", "SE3_1", "SE4_1", "SE5_1", "SE6_1", "SE7_1", "SE8_1", "SE9_1",
"SE10_1", "SE11_1", "SE12_1", "SE13_1", "SE14_1", "SE15_1", "SE16_1", "SE17_1", "SE18_1", "SE19_1", "SE20_1", "SE21_1")
names(data_ses) <- newnames
data <- merge(data_ses, data, by="ResponseId") #merge with main dataset
data$Condition <- factor(data$Condition,
levels = c("data_se.DBPrac", "data_se.REPrac"),
labels = c("Dialectical Bootstrapping", "Repeated Estimates"))
### COMBINING VARIABLES
## Reverse Score
columnsToReverse <- c("OMC_1", "OMC_2", "OMC_3",
"X1_Ambivalence1T1_3", "X1_Ambivalence1T1_5", "X1_Ambivalence1T1_7",
"X2_Ambivalence1T1_3", "X2_Ambivalence1T1_5", "X2_Ambivalence1T1_7",
"X1_Ambivalence1T2_3", "X1_Ambivalence1T2_5", "X1_Ambivalence1T2_7",
"X2_Ambivalence1T2_3", "X2_Ambivalence1T2_5", "X2_Ambivalence1T2_7")
data[,columnsToReverse] <- 8-data[,columnsToReverse]
## Compute Alphas
# by time and attitude
X1Ambiv <- data.frame(data[,grep("X1_Ambivalence", names(data))]) #create dataset with just X1 Ambiv measures
aX1_AmbivalenceT1 <- psych::alpha(data.frame(X1Ambiv[,grep("T1", names(X1Ambiv))])) #subset T1 and calc alpha
aX1_AmbivalenceT2 <- psych::alpha(data.frame(X1Ambiv[,grep("T2", names(X1Ambiv))])) #subset T2 and calc alpha
X2Ambiv <- data.frame(data[,grep("X2_Ambivalence", names(data))]) #create dataset with just X2 Ambiv measures
aX2_AmbivalenceT1 <- psych::alpha(data.frame(X1Ambiv[,grep("T1", names(X1Ambiv))])) #subset T1 and calc alpha
aX2_AmbivalenceT2 <- psych::alpha(data.frame(X1Ambiv[,grep("T2", names(X1Ambiv))])) #subset T2 and calc alpha
aX1_CertaintyT1 <- psych::alpha(data.frame(data[,grep("X1_CertaintyT1", names(data))]))
aX1_CertaintyT2 <- psych::alpha(data.frame(data[,grep("X1_CertaintyT2", names(data))]))
aX2_CertaintyT1 <- psych::alpha(data.frame(data[,grep("X2_CertaintyT1", names(data))]))
aX2_CertaintyT2 <- psych::alpha(data.frame(data[,grep("X2_CertaintyT2", names(data))]))
#entire scales
aAmbivalence <- psych::alpha(data.frame(data[,grep("Ambivalence", names(data))]))
aCertainty <- psych::alpha(data.frame(data[,grep("Certainty", names(data))]))
aOMC <- psych::alpha(data.frame(data[,grep("OMC", names(data))]))
aNFCS <- psych::alpha(data.frame(data[,grep("NFC", names(data))]))
alphas <- c(aX1_AmbivalenceT1$total$raw_alpha, aX1_CertaintyT1$total$raw_alpha,
aX1_AmbivalenceT2$total$raw_alpha, aX1_CertaintyT2$total$raw_alpha,
aX2_AmbivalenceT1$total$raw_alpha, aX2_CertaintyT1$total$raw_alpha,
aX2_AmbivalenceT2$total$raw_alpha, aX2_CertaintyT2$total$raw_alpha,
aOMC$total$raw_alpha, aNFCS$total$raw_alpha)
variables <- c("T1 Ambivalence (HR)", "T1 Certainty (HR)",
"T2 Ambivalence (HR)", "T2 Certainty (HR)",
"T1 Ambivalence (XR)", "T1 Certainty (XR)",
"T2 Ambivalence (XR)", "T2 Certainty (XR)",
"OMC", "NFCS")
items <- c("9", "4",
"9", "4",
"9", "4",
"9", "4",
"6", "15")
table_alphas <- data.frame(items, variables, alphas)
#1 how many do you think do not affiliate themselves with any religion?	45
#2 how many do you think are immigrants to this country (i.e. not born in this country?)	13
#3 how many do you think said they personally believe that homosexuality is morally unacceptable?	16
#4 how many do you think are Muslim?	5.2
#5 how many do you think said they personally believe that having an abortion is morally unacceptable?	25
#6 how many do you think die as a result of suicide?	1
#7 how many do you think die as a result of terrorism or conflict?	0.05
#8 how many do you think die as a result of cancer?	29.6
#9 how many do you think said their own health was very good or good?	74
#10	how many do you think said they personally believe that sex between unmarried adults is morally unacceptable?	11
#11	how many do you think are aged 14 or younger?	17
#12	how many do you think die due to disorders such as drug or alcohol addiction?	0.4
#13	how many do you think die as a result of interpersonal violence such as homicide or murder?	0.1
#14	how many do you think own a smartphone?	90.5
#15	how many do you think say they believe in hell?	21
#16	how many do you think say they believe in God?	39
#17	about how many working age people do you think are unemployed and looking for work?	4
#18	how many do you think have a Facebook account (who are old enough to have one, i.e. 13 and over)?	76
#19	how many do you think have access to the internet at home either through a computer or mobile device?	96
#20	how many said that, taking all things together, they are very happy or rather happy?	91.23
#21	how many do you think are either overweight or obese (excluding children)?	63
ListStim <- c("Religion (1)", "Immigrants (2)", "Homosexuality (3)", "Muslim (4)", "Terrorism/ Conflict (7)", "Cancer (8)",
"Health (9)", "Pre-Marital Sex (10)", "14 or Younger (11)", "Drug Deaths (12)", "Murders (13)",
"Smartphone (14)", "Believe in Hell (15)", "Believe in God (16)", "Unemployed (17)", "Facebook (18)",
"Internet Access (19)", "Happy (20)", "Overweight (21)")
Actual_Answers <- as.integer(TableStim$A) #value with actual answers
Actual_Answers <- Actual_Answers[-c(5, 6)] #remove stimuli for removed answers
#select questions, removing stimuli 5 and 6
qID <- c("1_1", "2_1", "3_1", "4_1", "7_1", "8_1", "9_1", "10_1",
"11_1", "12_1", "13_1", "14_1", "15_1", "16_1", "17_1", "18_1", "19_1", "20_1", "21_1")
### RQ1: Does DB improve accuracy?
## Error of FE Calculation per q
j <- 1 #set counter
for (i in qID){
FE <- paste("FE", qID[j], sep="") #identify FE
FE_E <- paste("FE_Error", qID[j], sep="") #compute new variable (error) name
data[FE_E] <- abs(Actual_Answers[j]-data[FE]) #absolute value of correct value vs first estimate per ppt
j <- j+1
}
# Median FE Error per ppt (median in line with Herzog (2009))
data$MedFE_Error <- apply(data[ grep("FE_Error", names(data))],1, median)
data$MeanFE_Error <- apply(data[ grep("FE_Error", names(data))],1, mean)
## Error of SE Calculation per q
j <- 1 #reset counter
for (i in qID){
SE <- paste("SE", qID[j], sep="") #identify FE
SE_E <- paste("SE_Error", qID[j], sep="") #compute new variable (error) name
data[SE_E] <- abs(Actual_Answers[j]-data[SE]) #absolute value of correct value vs first estimate per ppt
j <- j+1
}
# Median SE Error per ppt (median in line with Herzog (2009))
data$MedSE_Error <- apply(data[ grep("SE_Error", names(data))],1, median)
data$MeanSE_Error <- apply(data[ grep("SE_Error", names(data))],1, mean)
## Mean Estimate (FE+SE) Calculation per q
j <- 1 #reset counter
cols <- NULL
for (i in qID){
FE <- paste("FE", qID[j], sep="") #FE
SE <- paste("SE", qID[j], sep="") #SE
ME <- paste("ME", qID[j], sep="") #SE
data[ME] <- ((data[FE]+data[SE])/2)
j <- j+1
cols <- append(cols, ME)
}
data[,cols] <- lapply(data[,cols], as.integer)
## Error of Mean Estimate Calculation Per Q
j <- 1 #reset counter
for (i in qID){
ME <- paste("ME", qID[j], sep="") #identify FE
ME_E <- paste("ME_Error", qID[j], sep="") #compute new variable (error) name
data[ME_E] <- abs(Actual_Answers[j]-data[ME]) #absolute value of correct value vs first estimate per ppt
j <- j+1
}
# Median ME Error per ppt (median in line with Herzog (2009))
data$MedME_Error <- apply(data[ grep("ME_Error", names(data))],1, median)
data$MeanME_Error <- apply(data[ grep("ME_Error", names(data))],1, mean)
## Accuracy Gain per Q (Herzog, 2009)
j <- 1 #reset counter
for (i in qID){
FE_E <- paste("FE_Error", qID[j], sep="") #compute new variable (error) name
ME_E <- paste("ME_Error", qID[j], sep="") #identify ME error
AG <- paste("AG", qID[j], sep="") #create AG variable per q
data[AG] <- data[FE_E]-data[ME_E] #calculate AG per q
j <- j+1
}
# Median Accuracy Gain per participant
data$MedAG <- apply(data[ grep("AG", names(data))],1, median)
data$MeanAG <- apply(data[ grep("AG", names(data))],1, mean)
### RQ2: Does DB make people change estimates more?
j <- 1 #reset counter
for (i in qID){
FE <- paste("FE", qID[j], sep="") #FE Error[question]
SE <- paste("SE", qID[j], sep="") #SE Error[question]
EC <- paste("E_Change", qID[j], sep="") #SE Error[question]
data[EC] <- abs(data[FE]-data[SE])
j <- j+1
}
data$MedE_Change <- apply(data[ grep("E_Change", names(data))],1, median)
data$MeanE_Change <- apply(data[ grep("E_Change", names(data))],1, mean)
### RQ3: Is attitude ambivalence/ certainty change bigger in the DB condition?
poldnames <- c("X1_Ambivalence2T1_1",
"X1_Ambivalence2T1_2",
"X1_Ambivalence2T2_1",
"X1_Ambivalence2T2_2",
"X2_Ambivalence2T1_1",
"X2_Ambivalence2T1_2",
"X2_Ambivalence2T2_1",
"X2_Ambivalence2T2_2")
pnewnames <- c("X1_Ambivalence1T1_8",
"X1_Ambivalence1T1_9",
"X1_Ambivalence1T2_8",
"X1_Ambivalence1T2_9",
"X2_Ambivalence1T1_8",
"X2_Ambivalence1T1_9",
"X2_Ambivalence1T2_8",
"X2_Ambivalence1T2_9")
setnames(data, poldnames, pnewnames, skip_absent=TRUE)
setnames(data, "X1_ContentT1", "HRContT1", skip_absent=TRUE) #rename content column for consistency
setnames(data, "X1_ContentT2", "HRContT2", skip_absent=TRUE) #rename content column for consistency
data$HRAmbivT1 <- apply(data[,grep("X1_Ambivalence1T1", names(data))],1, mean)
data$HRAmbivT2 <- apply(data[,grep("X1_Ambivalence1T2", names(data))],1, mean)
data$HRStrT1 <- apply(data[,grep("X1_CertaintyT1", names(data))],1, mean)
data$HRStrT2 <- apply(data[,grep("X1_CertaintyT2", names(data))],1, mean)
setnames(data, "X2_ContentT1", "XRContT1", skip_absent=TRUE) #rename content column for consistency
setnames(data, "X2_ContentT2", "XRContT2", skip_absent=TRUE) #rename content column for consistency
data$XRAmbivT1 <- apply(data[,grep("X2_Ambivalence1T1", names(data))],1, mean)
data$XRAmbivT2 <- apply(data[,grep("X2_Ambivalence1T2", names(data))],1, mean)
data$XRStrT1 <- apply(data[,grep("X2_CertaintyT1", names(data))],1, mean)
data$XRStrT2 <- apply(data[,grep("X2_CertaintyT2", names(data))],1, mean)
### Combine OMC and NFCS items
data$OMC <- apply(data[,grep("OMC", names(data))],1, mean)
data$NFCS <- apply(data[,grep("NFC", names(data))],1, mean)
data$OpenMind <- (data$OMC+(8-data$NFCS))/2
#reorder dataset to match Qualtrics
variables <- c("ResponseId", #select variables necessary for analyses
grep("Duration", names(data), value=TRUE),
"Condition",
grep("HR", names(data), value=TRUE),
grep("XR", names(data), value=TRUE),
grep("FE", names(data), value=TRUE),
grep("SE", names(data), value=TRUE),
grep("ME", names(data), value=TRUE),
grep("AG", names(data), value=TRUE),
grep("E_Change", names(data), value=TRUE),
"OMC",
"NFCS",
"OpenMind",
"Age",
"Gender",
"Education",
"Manipulation.Check",
"Purpose",
"Comments",
"Source")
data <- data[, variables] #necessary variables for analysis
data[data == -99] <- NA
data_DB <- subset(data, Condition=="Dialectical Bootstrapping")
data_RE <- subset(data, Condition=="Repeated Estimates")
data$scaledOMC <- scale(data$OMC, scale=TRUE, center=TRUE)
data$scaledNFCS <- scale(data$NFCS, scale=TRUE, center=TRUE)
data_long <- reshape(data, direction='long', #long data by time
varying=list(Error=c("MeanFE_Error", "MeanSE_Error"),
HRCont=c("HRContT1", "HRContT2"),
HRAmbiv=c("HRAmbivT1", "HRAmbivT2"),
HRStr=c("HRStrT1", "HRStrT2"),
XRCont=c("XRContT1", "XRContT2"),
XRAmbiv=c("XRAmbivT1", "XRAmbivT2"),
XRStr=c("XRStrT1", "XRStrT2")),
timevar='Time',
times=c('T1', 'T2'),
v.names=c("Error",
"HRCont", "HRAmbiv", "HRStr",
"XRCont", "XRAmbiv", "XRStr"),
idvar="ResponseId")
data_DB_long <- subset(data_long, Condition=="Dialectical Bootstrapping")
data_RE_long <- subset(data_long, Condition=="Repeated Estimates")
data_t1 <- subset(data_long, Time=="T1")
data_t2 <- subset(data_long, Time=="T2")
### Preliminary - raw accuracy between estimates
anovaAccuracy <- aov(Error ~ Condition*Time + Error(ResponseId/Time),
data=data_long)
summary(anovaAccuracy)
### RQ1: Does DB improve accuracy?
RQ1_levene <- leveneTest(MeanAG~Condition, data=data)
RQ1_levene_apa <- apa_print(RQ1_levene)
RQ1_t <- t.test(MeanAG~Condition, data=data)
summary(RQ1_t)
RQ1_t_apa <- apa_print(RQ1_t)
### RQ2: Does DB make people change estimates more?
RQ2_levene <- leveneTest(MeanE_Change~Condition, data=data)
RQ2_levene_apa <- apa_print(RQ2_levene)
RQ2_t <- t.test(MeanE_Change~Condition, data=data)
RQ2_t_apa <- apa_print(RQ2_t)
### RQ3: Is attitude ambivalence/ certainty change bigger in the DB condition?
data_long_DB <- subset(data_long, Condition=="Dialectical Bootstrapping")
data_long_RE <- subset(data_long, Condition=="Repeated Estimates")
data_long_T1 <- subset(data_long, Time=="T1")
data_long_T2 <- subset(data_long, Time=="T2")
data_long_DB_T1 <- subset(data_long,
Condition=="Dialectical Bootstrapping" & Time=="T1")
data_long_DB_T2 <- subset(data_long,
Condition=="Dialectical Bootstrapping" & Time=="T2")
data_long_RE_T1 <- subset(data_long,
Condition=="Repeated Estimates" & Time=="T1")
data_long_RE_T2 <- subset(data_long,
Condition=="Repeated Estimates" & Time=="T2")
data_long$Id2 <- paste(data_long$ResponseId, data_long$Time, sep="")
data_long_att <- reshape(data_long, direction='long', #long data by time and topic
varying=list(Cont=c("HRCont", "XRCont"),
Ambiv=c("HRAmbiv","XRAmbiv"),
Str=c("HRStr","XRStr")),
timevar='Topic',
times=c('HR', 'XR'),
v.names=c("Cont", "Ambiv", "Str"),
idvar="Id2")
#Correlation between HR and XR
cor_cont <- cor.test(data_long$HRCont, data_long$XRCont)
cor_str <- cor.test(data_long$HRStr, data_long$XRStr)
cor_ambiv <- cor.test(data_long$HRAmbiv, data_long$XRAmbiv)
anovaHRCont <- aov(HRCont ~ Condition*Time + Error(ResponseId/Time),
data=data_long)
summary(anovaHRCont)
anovaHRCont_apa <- apa_print(anovaHRCont)
anovaHRStr <- aov(HRStr ~ Condition*Time + Error(ResponseId/Time),
data=data_long)
summary(anovaHRStr)
model.tables(anovaHRStr, "means")
anovaHRStr_apa <- apa_print(anovaHRStr)
anovaHRAmbiv <- aov(HRAmbiv ~ Condition*Time + Error(ResponseId/Time),
data=data_long)
summary(anovaHRAmbiv)
model.tables(anovaHRAmbiv, "means")
anovaHRAmbiv_apa <- apa_print(anovaHRAmbiv)
#post hoc - interaction
anovaHRAmbivDB <- aov(HRAmbiv ~ Time + Error(ResponseId/Time),
data=data_DB_long)
summary(anovaHRAmbivDB)
anovaHRAmbivDB_apa <- apa_print(anovaHRAmbivDB)
anovaHRAmbivRE <- aov(HRAmbiv ~ Time + Error(ResponseId/Time),
data=data_RE_long)
summary(anovaHRAmbivRE)
anovaHRAmbivRE_apa <- apa_print(anovaHRAmbivRE)
anovaHRAmbivT1 <- aov(HRAmbiv ~ Condition,
data=data_t1)
summary(anovaHRAmbivT1)
anovaHRAmbivT1_apa <- apa_print(anovaHRAmbivT1)
anovaHRAmbivT2 <- aov(HRAmbiv ~ Condition,
data=data_t2)
summary(anovaHRAmbivT2)
anovaHRAmbivT2_apa <- apa_print(anovaHRAmbivT2)
anovaXRCont <- aov(XRCont ~ Condition*Time + Error(ResponseId/Time),
data=data_long)
summary(anovaXRCont)
model.tables(anovaXRCont, "means")
anovaXRCont_apa <- apa_print(anovaXRCont)
#post hoc - interaction
anovaXRContDB <- aov(XRCont ~ Time + Error(ResponseId/Time),
data=data_DB_long)
summary(anovaXRContDB)
anovaXRContDB_apa <- apa_print(anovaXRContDB)
anovaXRContRE <- aov(XRCont ~ Time + Error(ResponseId/Time),
data=data_RE_long)
summary(anovaXRContRE)
anovaXRContRE_apa <- apa_print(anovaXRContRE)
anovaXRContT1 <- aov(XRCont ~ Condition,
data=data_t1)
summary(anovaXRContT1)
anovaXRContT1_apa <- apa_print(anovaXRContT1)
anovaXRContT2 <- aov(XRCont ~ Condition,
data=data_t2)
summary(anovaXRContT2)
anovaXRContT2_apa <- apa_print(anovaXRContT2)
anovaXRAmbiv <- aov(XRAmbiv ~ Condition*Time + Error(ResponseId/Time),
data=data_long)
summary(anovaXRAmbiv)
model.tables(anovaXRAmbiv, "means")
anovaXRAmbiv_apa <- apa_print(anovaXRAmbiv)
anovaXRStr <- aov(XRStr ~ Condition*Time + Error(ResponseId/Time),
data=data_long)
summary(anovaXRStr)
model.tables(anovaXRStr, "means")
anovaXRStr_apa <- apa_print(anovaXRStr)
### RQ4: Do OMC/ NFCS affect RQs 1, 2 and 3?
#RQ4.1 Do OMC/ NFCS affect RQ1
RQ4.1 <- lm(data=data, MeanAG ~ Condition * scaledOMC * scaledNFCS)
summary(RQ4.1)
vif(RQ4.1)
RQ4.1_apa <- apa_print(RQ4.1)
#RQ4.2 Do OMC/ NFCS affect RQ2
RQ4.2 <- lm(data=data, MeanE_Change ~ Condition * scaledOMC * scaledNFCS)
summary(RQ4.2)
RQ4.2_vif <- vif(RQ4.2)
RQ4.2_apa <- apa_print(RQ4.2)
#RQ4.3 Do OMC/ NFC affect RQ3?
lm <- lm(data=data_long, HRCont ~ Condition*Time*(scaledNFCS+scaledOMC))
summary(lm)
lm <- lm(data=data_long, XRCont ~ Condition*Time*(scaledNFCS+scaledOMC))
summary(lm)
lm <- lm(data=data_long, HRAmbiv ~ Condition*Time*(scaledNFCS+scaledOMC))
summary(lm)
lm <- lm(data=data_long, XRAmbiv ~ Condition*Time*(scaledNFCS+scaledOMC))
summary(lm)
lm <- lm(data=data_long, HRStr ~ Condition*Time*(scaledNFCS+scaledOMC))
summary(lm)
lm <- lm(data=data_long, XRStr ~ Condition*Time*(scaledNFCS+scaledOMC))
summary(lm)
length(which(data_raw$Manipulation.Check==0))
length(which(data_DB$Manipulation.Check==0))
length(which(data_DB$Manipulation.Check==1))
length(which(data_DB$Manipulation.Check==2))
?apa_table
??apa_table
Table <- read.csv("data/PerilsStimuli.csv") #prolific dataset
Table <- read.csv("data/PerilsStimuli.csv") #prolific dataset
Table <- read.csv("data/PerilsStimuli.csv") #prolific dataset
Table <- read.csv("data/PerilsStimuli.csv") #prolific dataset
Table <- read.csv("data/PerilsStimuli.csv") #prolific dataset
Table <- read.csv("data/PerilsStimuli.csv") #prolific dataset
Table <- read.csv("data/PerilsStimuli.csv") #prolific dataset
apa_table(RQ4.2_apa$table,
caption="Multivariate linear regression model for estimate change with condition as a categorical predictor (with dialectical bootstrapping as the reference condition), and OMC and NFCS as continious predictors, including all possible two- and three-way interaction terms. OMC and NFCS were scaled via mean centering for the purpose of the regression.",
placement="h",
font_size="footnotesize")
