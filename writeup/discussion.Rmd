---
bibliography: references.bib
---

# Discussion {.unnumbered}

This study aimed to investigate whether the *dialectical bootstrapping* paradigm could be adapted to reducing dogmatism by causing individuals to rethink the assumptions behind their beliefs and judgements both within the paradigm itself, and causing spillover effects to pro-environmental attitudes. In contrast to previous studies using other types of stimuli [e.g. @herzog2009], but in line with the pilot study, accuracy gain was not found by averaging dialectical estimates with initial ones. Despite this, participants given the dialectical instructions were more likely to make larger changes to their second estimates in comparison to their first; a difference of `r round(mean(data_DB$MeanE_Change)/mean(data_RE$MeanE_Change),2)`x. This replicates the post hoc finding from the pilot study *a priori*. However, this did not translate into consistent patterns of pro-environmental attitude change, an increase in attitude ambivalence nor decreases in certainty, and these differences in estimate change were not related to measures of Open-Minded Cognition or Need for Closure.

Despite the lack of greater accuracy gain in the dialectical bootstrapping condition, there is clear evidence that the dialectical bootstrapping procedure within the study caused *some* changes to the way participants make estimates, and by extension think about the assumptions and beliefs behind those estimations. Participants *did* change their second estimates more compared to the first in the dialectical bootstrapping condition to a reasonably large degree (`r round(mean(data_DB$MeanE_Change),2)`% vs `r round(mean(data_RE$MeanE_Change),2)`%), suggesting they successful engaged with the dialectical thought processes elicited by the instructions and changed the assumptions behind their estimations.

This was coupled by greater variance in accuracy gain within the *dialectical bootstrapping* condition, which had a much higher standard deviation (*SD*=`r round(sd(data_DB$MeanAG),2)`%) than the *repeated estimates* condition (*SD*=`r round(sd(data_RE$MeanAG),2)`%). As suggested by Figure \@ref(fig:plotAG)a, dialectical bootstrapping seemed to magnify the degree of accuracy gain participants would see by averaging their two estimates. Those who saw a positive accuracy gain saw much larger ones than those in the repeated estimates condition, but this was equally true of those who generally saw a negative effect of averaging estimates. This suggests that for some stimuli, not only may dialectical bootstrapping not serve to improve estimates, but it may serve to also exaggerate deficiencies in repeated estimation.

It is difficult to say whether this generalises to social phenomena more widely from the limited 19 items included in the analysis of this study. As shown by Figure \@ref(fig:plotests) and corroborated by the *Perils in Perception* data-sets [@ipsosmori2016; @ipsosmori2017; @ipsosmori2018; @ipsosmori2020; @ipsosmori2021], very few of the distributions of estimates actually "bracketed" the true values, suggesting that there may not even be a "wisdom of the crowds" effect in these type of stimuli. Indeed, the *"Perils"* in the *Perils in Perception* were that people tended to systematically under- or over-estimate their perceptions of social phenomena. Participants asked to think about their assumptions being wrong may thus draw on knowledge of what others think; in this case, unlike for stimuli such as dates, people may correctly recognise that others generally share the same biases they do, and thus serve only to moderate or amplify this bias rather than consider a directly opposite assumption. However, without knowing the distribution of estimates presented in prior studies such as @herzog2009 and @litvinova2020, it is difficult to conclude that it was necessarily this property of social estimations that causes this difference. Future studies should aim to compare whether accuracy gain is seen for stimuli with a wide variety of different properties, such as in terms of whether estimate distributions across participants tend to "bracket" the true value. Probing participants further about the cognitive processes they engaged in whilst making estimates may also help to elucidate whether there are significant differences between the type of thought processes elicited by dialectical instructions for social phenomena like in this study or for more factual stimuli like in @herzog2009.

Although participants in the dialectical bootstrapping condition appeared to become more open-minded to changing the assumptions behind their estimates from changing their estimates more than participants in the repeated estimates condition, this did not extend to overall trends in greater attitude change or reductions in attitude strength (outside of a spurious difference in attitude strength for *household recycling* and a very small difference in the *repeated estimates* condition for *Extinction Rebellion* attitude content). The interaction terms for ambivalence were significant for both topics, but these had very small effect sizes and were not able to be meaningfully interpreted with post hoc testing, with all post hoc tests remaining statistically non-significant with the appropriate corrections for multiple comparisons. This is perhaps not surprising given participants were not given the same dialectical instructions when providing attitude measurements, nor were they given any persuasive information to attempt to change their attitudes. This was a known compromise to the current study, as this dialectical bootstrapping paradigm has not previously been established as a tool for social psychological research. As such, the primary aim of this study was to develop the paradigm for future use in studies of this vein, and so persuasive material (which would have entailed adding an additional *for* and *against* condition) was not included in order to maintain appropriate statistical power within current funding and practical recruitment constraints. However, given the greater open-mindedness observed *within* the task, a future study may aim to see whether dialectical instructions causes participants to be more open-minded to counter-attitudinal persuasive information.

Given the lack of significance, little can be gleaned from the relationships between OMC and NFCS with the dialectical bootstrapping procedures in terms of boundary conditions for dialectical bootstrapping. It is possible that this relationship is smaller than the power allowed by this study; indeed, there were some effects of NFCS that were marginally significant (*p*s<.10), but these cannot be confidently interpreted from the current findings. Future studies may still wish to investigate whether personality variables such as these moderate the dialectical bootstrapping process, but may wish to do so either with the more established dates paradigm used by @herzog2009 and @litvinova2020 that does tend to find much greater accuracy gain effects or with a far larger sample size to enable greater statistical power.

## Methodological Issues and Discussion {.unnumbered}

There were potential important differences in the mode of delivery in this study compared to previous studies that could affect the efficacy of dialectical bootstrapping. @herzog2009 administered the study listing the stimuli on a physical sheet of paper and asking participants to write down their answers using a pen, whilst this study was administered online, with participants viewing each question individually and responding using a slider. Firstly, presenting the stimuli individually rather than together may have reduced the extent to which comparative thinking, approaching the assumptions behind their responses to the items together and comparing their thought processes behind each. This may have allowed for greater consideration of which assumptions to change. However, when considering all their estimates in one go, participants may have engaged more in overall comparative thinking and been more willing to review their assumptions overall, as seen in general research on comparative thinking [@mussweiler2012]. However, this is not particularly likely, as the pilot study referenced in this paper also presented the stimuli together in a list and failed to find a strong accuracy gain effect. The presentation medium and study environment may not be so inconsequential. There is a growing body of research suggesting that print-based text is more deeply comprehended than the same text presented digitally, with effects including greater reading comprehension and success in persuasion from print-based media [@haddock2019]; furthermore, unique characteristics of the environment in laboratory-based studies may also encourage this deeper level of processing [e.g. @dandurand2008; @hanel2016]. As such, participants may not have engaged with the dialectical bootstrapping process in this study as effectively as they did in prior studies that did find an accuracy gain effect [e.g. @herzog2009]. Future studies may wish to directly investigate this claim by comparing lab-based to online participants and print-based to online-based presentation mediums.

## Practical Implications {.unnumbered}

So what of dialectical bootstrapping as a means to improve sustainability by reducing dogmatism? Combined with the pilot study, this study does provide good reason to believe that encouraging participants to think dialectically resulted in them being more likely to change the assumptions behind their thoughts. This is evidenced *within* the task as participants changed their estimates far more in the dialectical bootstrapping condition than the repeated estimates condition. Could this change have been driven by processes other than a change in assumptions? Possibly. Participants were not directly asked about their thought processes behind each estimate they made; furthermore, no aspect of the study paradigm allowed a deeper look at the mechanisms behind participants' estimate changes. It is thus possible that the greater changes in estimates seen in this study are due to dialectical bootstrapping encouraging change without necessarily getting participants to engage in the deeper level of thinking required to change assumptions. However, combined with the positive accuracy findings of @herzog2009 and all but `r length(which(data_DB$Manipulation.Check==2))` participants in the *dialectical bootstrapping* condition failing to recognise that they had been asked to assume their assumptions were off the mark, we believe that this change is due to a difference in assumptions; but unlike in the findings from @herzog2009, this change from dialectical thinking did not necessarily result in directly opposite assumptions, and instead a more moderate modification to previously held assumptions. This would explain why greater change was seen in the dialectical bootstrapping condition, although it would still be beneficial for future research to further investigate the thought processes of participants asked to engage in dialectical estimates.

Despite this, the study has failed to effectively demonstrate dialectical bootstrapping as a means to encourage open-minded thinking *outside* of the task and thus as an effective method of encouraging open-minded thinking in pro-environmental attitudes and behaviours. As discussed earlier, this may be a consequence of not providing the most appropriate stimuli to test this hypothesis. Thus, whilst this study has not conclusively demonstrated that dialectical bootstrapping can cause reductions in dogmatism and close-minded thinking outside of the main estimation task itself, the evidence within the task provides good empirical backing to further pursuing dialectical bootstrapping as an intervention to reduce dogmatism with more appropriate measures.

## Conclusion {.unnumbered}

Overall, attempts to adapt dialectical bootstrapping to a more social psychologically targeted paradigm have had mixed success. The intervention is doing *something;* participants given dialectical instructions did change their estimates far more than those merely asked to provide repeat estimates. However, this difference did not translate into replication of prior results regarding improved *accuracy*, and this had no bearing on changes in pro-environmental attitude content, strength or ambivalence for either mundane or controversial attitude objects. Furthermore, little was learnt about the mechanisms behind this difference in estimate change between conditions, as there were no relations to measures of open-mindedness. Future research should aim to directly uncover more about the mechanisms causing the greater changes between estimate in those asked to think dialectically, and attempt to translate them more directly to attitude change by introducing attempts at persuasion. Dialectical bootstrapping may not be a silver bullet that increases accuracy for all types of estimations, but it undoubtedly shows promise as a tool to encourage open-minded thinking. Harnessing these changes outside of an estimation task setting remains the key challenge in translating these effects to real-world interventions to improve sustainable thinking and action.